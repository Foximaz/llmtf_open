# Benchmark Results: ru_arena-hard-v0.1
**Judge Model:** deepseek

## Model Performance Summary

| Model | ELO Rating | STD | 95% CI | Median Length (chars) |
|-------|------------|-----|--------|-------------------|
| T-pro-it-2.0 | 1615 | 22 | [1578, 1663] | 2271 |
| T-pro-it-2.0-think | 1572 | 18 | [1543, 1612] | 2138 |
| Qwen3-235B-A22B-Instruct-2507 | 1523 | 10 | [1504, 1544] | 1858 |
| RuadaptQwen3-32B-Instruct-think | 1284 | 14 | [1258, 1309] | 1693 |
| RuadaptQwen3-32B-Instruct | 1252 | 15 | [1229, 1283] | 1592 |
| RuadaptQwen3-4B-Instruct-think | 1170 | 14 | [1142, 1196] | 1732 |
| QVikhr-3-4B-Instruction-think | 1142 | 13 | [1114, 1165] | 1624 |
| RuadaptQwen3-4B-Instruct | 1120 | 13 | [1095, 1142] | 1460 |
| QVikhr-3-4B-Instruction | 1112 | 13 | [1082, 1135] | 1645 |
| gigachat_max_26.20_uncen | 1103 | 13 | [1080, 1129] | 994 |
| Qwen3-4B-think | 1056 | 14 | [1031, 1087] | 1479 |
| gpt-4-1106-preview | 1036 | 7 | [1023, 1052] | 1261 |
| Qwen3-4B | 1029 | 13 | [1004, 1056] | 1627 |
| gpt-4o-mini | 1000 | 0 | [1000, 1000] | 876 |
| Qwen2.5-32B-Instruct | 903 | 17 | [870, 936] | 976 |
| Qwen3-1.7B-think | 877 | 15 | [853, 909] | 1398 |
| Qwen3-1.7B | 765 | 23 | [723, 801] | 1681 |