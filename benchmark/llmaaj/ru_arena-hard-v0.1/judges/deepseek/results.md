# Benchmark Results: ru_arena-hard-v0.1
**Judge Model:** deepseek

## Model Performance Summary

| Model | ELO Rating | STD | 95% CI | Median Length (chars) |
|-------|------------|-----|--------|-------------------|
| T-pro-it-2.0 | 1620 | 22 | [1573, 1660] | 2271.0 |
| T-pro-it-2.0-think | 1576 | 21 | [1535, 1611] | 2138.0 |
| Qwen3-235B-A22B-Instruct-2507 | 1531 | 14 | [1506, 1557] | 1858.0 |
| RuadaptQwen3-32B-Instruct-think | 1284 | 17 | [1259, 1323] | 1693.0 |
| RuadaptQwen3-32B-Instruct | 1253 | 16 | [1227, 1284] | 1592.0 |
| RuadaptQwen3-4B-Instruct-think | 1170 | 16 | [1141, 1201] | 1732.0 |
| RuadaptQwen3-4B-Instruct | 1123 | 13 | [1094, 1149] | 1460.0 |
| gigachat_max_26.20_uncen | 1109 | 15 | [1082, 1139] | 994.0 |
| Qwen3-4B-think | 1054 | 17 | [1029, 1091] | 1479.0 |
| gpt-4-1106-preview | 1048 | 9 | [1029, 1067] | 1261.0 |
| Qwen3-4B | 1032 | 15 | [1007, 1063] | 1627.0 |
| gpt-4o-mini | 1000 | 0 | [1000, 1000] | 876.0 |
| Qwen2.5-32B-Instruct | 905 | 21 | [871, 952] | 976.0 |