#TODO: обработка few-shot не с 0 до K, а сразу с K, а затем уменьшать, если не влезает. (должно существенно ускорить подготовку данных)

#TODO: task gen config context

#TODO: num_return_sequences > 1.

#TODO: bugs with infos.

#TODO: метод расчета перплексии.

#TODO: единый стиль кавычек: перейти на двойные.

#TODO: распараллелить препроцессинг датасетов

#TODO: typing, сигнатуры, докстринги.

#TODO: vllm lora: корректно извлечь макс ранг. + тесты.

#TODO: ООП и другие приколы питона (где бы найти норм кодстайл?)

#TODO: генерация сабмитов под RSG, MERA, RuCoLa. В 2 этапа: 1) обработка таски/тасок 2) конвертация результата в нужный формат.

#TODO: (возможно) генерация с оценкой качества через alpaca-eval

#TODO: post task eval аналитика: на rutie оценить поведение на разных длинах, в целом можно попробовать оценить вероятность data contamination

#TODO: баг с тем, что "разделители" сообщений могут влиять на итоговую токенизацию (в основном речь про \n в ллама-3). Скорее всего токенизироваться нужно тоже в conversation классе шаг за шагом, разделители отдельно.